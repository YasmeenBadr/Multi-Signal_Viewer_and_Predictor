<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voice Processing Suite</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            /* Applied Inter font family */
            font-family: 'Inter', sans-serif; 
            /* Subtle, dark radial gradient background for a "digital" feel */
            background: radial-gradient(circle at top, #121212 0%, #0a0a0a 100%);
            color: white;
            overflow-x: hidden;
        }
        .main-color {
            color: #00eaff; /* Neon Cyan */
        }
        .glass-card {
            /* Defines the "Glassmorphism" effect */
            backdrop-filter: blur(12px);
            background: rgba(31, 31, 31, 0.7);
            /* Subtle neon border */
            border: 1px solid rgba(0, 234, 255, 0.2);
            box-shadow: 0 0 20px rgba(0, 234, 255, 0.05);
            transition: all 0.4s ease;
        }
        .glass-card:hover {
            border-color: rgba(0, 234, 255, 0.5);
            box-shadow: 0 0 25px rgba(0, 234, 255, 0.15);
            transform: translateY(-2px);
        }
        .drag-area {
            /* Neon dashed border for the active/upload area */
            border: 2px dashed #00eaff;
            background-color: rgba(15, 15, 15, 0.8);
            transition: 0.4s ease;
            backdrop-filter: blur(6px);
        }
        .drag-area.drag-over {
            /* Active state for drag-over */
            background-color: rgba(0, 234, 255, 0.1);
            border-color: #00eaff;
            box-shadow: 0 0 12px rgba(0, 234, 255, 0.3);
        }
        /* Custom styling for the range slider thumb for neon look */
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 18px;
            height: 18px;
            border-radius: 50%;
            background: #00eaff;
            cursor: pointer;
            box-shadow: 0 0 10px #00eaff;
        }
        .btn-control {
            /* NEW: Uniform, minimalist button styling */
            background: rgba(45, 45, 45, 0.8); /* Darker glass background */
            border: 1px solid rgba(100, 100, 100, 0.4);
            color: #fff;
            transition: all 0.3s ease;
            position: relative;
        }
        /* NEW: Neon glow border on hover is kept, but with a universal background */
        .btn-control::after {
            content: "";
            position: absolute;
            inset: 0;
            border-radius: 9999px;
            border: 1px solid rgba(0, 234, 255, 0.2);
            transition: all 0.3s ease;
        }
        .btn-control:hover {
            background: rgba(60, 60, 60, 0.9);
        }
        .btn-control:hover::after {
            border-color: rgba(0, 234, 255, 0.6);
            box-shadow: 0 0 10px rgba(0, 234, 255, 0.3);
        }
        /* NEW: Removed text-shadow for main title */
        .neon-title {
            /* text-shadow removed */
        }
        
        /* NEW: Gender-specific styles for the classification results container */
        .results-male {
            border-color: #3b82f6; /* Blue-500 */
            box-shadow: 0 0 25px rgba(59, 130, 246, 0.25);
        }
        .results-female {
            border-color: #ec4899; /* Pink-500 */
            box-shadow: 0 0 25px rgba(236, 72, 153, 0.25);
        }

        /* Creative accent bar */
        .gender-accent-bar {
            height: 8px;
            width: 100%;
            border-radius: 9999px;
            margin-bottom: 20px;
            transition: background 0.5s ease;
        }
        .gender-accent-bar-male {
            background: linear-gradient(90deg, #3b82f6 0%, #00eaff 100%);
        }
        .gender-accent-bar-female {
            background: linear-gradient(90deg, #ec4899 0%, #f472b6 100%);
        }

        /* Recording indicator animation */
        @keyframes pulse-red {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        .recording-indicator {
            animation: pulse-red 1.5s ease-in-out infinite;
        }
        
        .record-btn-active {
            background: rgba(220, 38, 38, 0.9) !important;
            border-color: rgba(239, 68, 68, 0.6) !important;
        }
    </style>
</head>

<body class="min-h-screen flex flex-col items-center justify-center p-6">
    <div class="max-w-5xl w-full text-center space-y-8 animate-fade-in">
        
        <header class="mb-12">
            <h1 class="text-5xl md:text-6xl font-extrabold main-color tracking-wide">
                Voice Processing Suite
            </h1>
            <p class="text-gray-300 text-lg md:text-xl mt-4">
                Experiment with audio fidelity and discover how **sampling rates** affect sound clarity.
            </p>
        </header>

        <div class="glass-card rounded-3xl p-8 md:p-12 shadow-2xl mx-auto w-full">
            <h2 class="text-3xl font-semibold mb-8 text-white">Sampling Rate Demonstrator & Analysis</h2>

            <section class="mb-10">
                <!-- Voice Recording Section -->
                <div class="mb-8 p-6 rounded-2xl bg-gray-800 bg-opacity-50 border border-gray-700">
                    <h3 class="text-xl font-semibold mb-4 text-white flex items-center justify-center gap-2">
                        <svg class="w-6 h-6 text-red-400" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
                        </svg>
                        Record Your Voice
                    </h3>
                    <div class="flex flex-col items-center gap-4">
                        <div class="flex gap-3">
                            <button id="recordBtn" class="btn-control text-white font-bold py-3 px-8 rounded-full flex items-center gap-2">
                                <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20">
                                    <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clip-rule="evenodd"></path>
                                </svg>
                                Start Recording
                            </button>
                            <button id="stopRecordBtn" class="btn-control text-white font-bold py-3 px-8 rounded-full flex items-center gap-2 disabled:opacity-30" disabled>
                                <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20">
                                    <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clip-rule="evenodd"></path>
                                </svg>
                                Stop Recording
                            </button>
                        </div>
                        <div id="recordingStatus" class="text-sm text-gray-400 h-6"></div>
                        <div id="recordingTimer" class="hidden text-2xl font-mono main-color">00:00</div>
                    </div>
                </div>

                <!-- File Upload Section -->
                <div class="text-center mb-4">
                    <p class="text-gray-400 text-sm">OR</p>
                </div>
                <div id="dragDropArea" class="drag-area p-10 rounded-2xl text-center cursor-pointer hover:shadow-lg" onclick="document.getElementById('fileInput').click()">
                    <p id="filePrompt" class="text-gray-300 font-medium">
                        **Drag & Drop** an MP3/WAV audio file here, or **click to upload**.
                    </p>
                    <p id="fileNameDisplay" class="text-green-400 mt-3 hidden text-sm font-mono"></p>
                    <input type="file" id="fileInput" accept="audio/*" class="hidden">
                </div>
            </section>

            <section id="controls" class="space-y-10 opacity-50 pointer-events-none transition-all duration-700">
                
                <div class="flex flex-col md:flex-row items-center justify-between gap-6 p-4 rounded-xl bg-gray-800 bg-opacity-50">
                    <label for="samplingFrequency" class="text-gray-300 font-semibold w-full md:w-1/3 text-left">Target Sample Rate:</label>
                    <div class="w-full md:w-2/3">
                        <input type="range" id="samplingFrequency" min="4000" max="44100" value="44100" step="100" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
                        <p class="text-sm text-gray-400 mt-2 text-right"><span id="currentFrequency" class="main-color font-bold">44100</span> Hz (Original Rate)</p>
                    </div>
                </div>

                <div class="flex justify-center flex-wrap gap-4 pt-4 border-t border-gray-700">
                    <button id="playOriginalBtn" class="btn-control text-white font-bold py-3 px-8 rounded-full flex items-center disabled:opacity-50" disabled>
                        Start Original
                    </button>
                    <button id="pauseBtn" class="btn-control text-white font-bold py-3 px-8 rounded-full flex items-center disabled:opacity-50" disabled>
                        Pause / Stop
                    </button>
                    <button id="playSampledBtn" class="btn-control text-white font-bold py-3 px-8 rounded-full flex items-center disabled:opacity-50" disabled>
                        Start Resampled
                    </button>
                </div>

                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 pt-6 border-t border-gray-700 mt-8">
                    <button id="classifyBtn" class="btn-control text-white font-bold py-3 px-10 rounded-full flex items-center justify-center disabled:opacity-50" disabled>
                        Analyze & Classify
                    </button>
                    
                    <button id="resetBtn" class="btn-control text-white font-bold py-3 px-10 rounded-full flex items-center justify-center disabled:opacity-40">
                        <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M4 4v5h.582m15.356 2A8.001 8.001 0 0014 4H5m7 12l-4-4m0 0l-4 4m4-4V4"></path></svg>
                        Reset Application
                    </button>
                </div>

                <div id="classificationResults" class="hidden mt-8 p-8 bg-gray-800 bg-opacity-70 rounded-2xl border-2 transition-all duration-500">
                    <div id="genderAccentBar" class="gender-accent-bar"></div>
                    <h3 class="text-2xl font-bold mb-4 text-white">Analysis Results</h3>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-6 text-center">
                        <div>
                            <p class="text-gray-400 text-sm mb-1">Gender</p>
                            <p id="genderResult" class="text-2xl font-bold">N/A</p>
                        </div>
                        <div>
                            <p class="text-gray-400 text-sm mb-1">Confidence</p>
                            <p id="confidenceResult" class="text-2xl font-bold text-green-400">N/A</p>
                        </div>
                        <div>
                            <p class="text-gray-400 text-sm mb-1">Average Pitch (F0)</p>
                            <p id="pitchResult" class="text-2xl font-bold text-cyan-400">N/A</p>
                        </div>
                    </div>
                </div>

                <p id="messageBox" class="text-sm text-red-400 mt-4 h-5"></p>
            </section>
        </div>

        <a href="/" class="inline-block mt-8 text-lg bg-gradient-to-r from-cyan-600 to-blue-600 hover:from-cyan-500 hover:to-blue-500 text-white font-bold py-3 px-8 rounded-full transition-transform hover:scale-105 shadow-lg">
            ‚Üê Back to Dashboard
        </a>
    </div>

    <script>
        let audioContext;
        let originalBuffer = null;
        let resampledBuffer = null;
        let originalRate = 44100;
        let isPlaying = false;
        let currentSourceNode = null;
        let uploadedFile = null; // Store the uploaded file for classification

        // Recording variables
        let mediaRecorder = null;
        let audioChunks = [];
        let recordingStream = null;
        let recordingStartTime = null;
        let recordingTimerInterval = null;

        const fileInput = document.getElementById('fileInput');
        const dragDropArea = document.getElementById('dragDropArea');
        const filePrompt = document.getElementById('filePrompt');
        const fileNameDisplay = document.getElementById('fileNameDisplay');
        const controls = document.getElementById('controls');
        const frequencySlider = document.getElementById('samplingFrequency');
        const currentFrequencyDisplay = document.getElementById('currentFrequency');
        const playOriginalBtn = document.getElementById('playOriginalBtn');
        const playSampledBtn = document.getElementById('playSampledBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const resetBtn = document.getElementById('resetBtn');
        const classifyBtn = document.getElementById('classifyBtn');
        const messageBox = document.getElementById('messageBox');
        const classificationResults = document.getElementById('classificationResults');
        const genderResult = document.getElementById('genderResult');
        const confidenceResult = document.getElementById('confidenceResult');
        const pitchResult = document.getElementById('pitchResult');
        const genderAccentBar = document.getElementById('genderAccentBar'); // NEW
        const recordBtn = document.getElementById('recordBtn');
        const stopRecordBtn = document.getElementById('stopRecordBtn');
        const recordingStatus = document.getElementById('recordingStatus');
        const recordingTimer = document.getElementById('recordingTimer');

        // Initialize AudioContext on first interaction
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                // Update slider max value to the native rate upon initialization
                frequencySlider.max = audioContext.sampleRate;
                frequencySlider.value = audioContext.sampleRate;
                currentFrequencyDisplay.textContent = audioContext.sampleRate;
                messageBox.textContent = `Native Sample Rate: ${audioContext.sampleRate} Hz`;
                originalRate = audioContext.sampleRate;
            }
        }
        
        // --- 1. Audio Loading and Decoding ---

        function decodeAudio(file) {
            uploadedFile = file; // Store for classification
            initAudioContext();
            const reader = new FileReader();

            reader.onload = function(event) {
                const arrayBuffer = event.target.result;
                audioContext.decodeAudioData(arrayBuffer, 
                    function(buffer) {
                        originalBuffer = buffer;
                        originalRate = buffer.sampleRate;
                        // Reset slider max/value based on the loaded file's rate
                        frequencySlider.max = originalRate;
                        frequencySlider.value = originalRate;
                        currentFrequencyDisplay.textContent = originalRate;
                        
                        resampleAudio(originalRate);
                        updateUI(file.name);
                    },
                    function(e) {
                        messageBox.textContent = "Error decoding audio data. Is the file corrupted?";
                        console.error("Audio decoding error:", e);
                    }
                );
            };

            reader.onerror = function() {
                messageBox.textContent = "Error reading file.";
            };

            reader.readAsArrayBuffer(file);
        }

        function updateUI(fileName) {
            controls.classList.remove('opacity-50', 'pointer-events-none');
            playOriginalBtn.disabled = false;
            playSampledBtn.disabled = false;
            resetBtn.disabled = false;
            classifyBtn.disabled = false;
            fileNameDisplay.textContent = `Loaded: ${fileName}`;
            fileNameDisplay.classList.remove('hidden');
            filePrompt.classList.add('hidden');
            messageBox.textContent = `File ready. Original rate: ${originalRate} Hz`;
        }

        // --- 2. Resampling Logic (Zero-order hold/Nearest neighbor for simplicity) ---
        
        function resampleAudio(targetRate) {
            if (!originalBuffer) return;

            const ratio = originalRate / targetRate;
            // The new length is determined by the ratio
            const newLength = Math.floor(originalBuffer.length / ratio);

            // Create a new buffer with the target number of samples
            // The sample rate *must* remain the original context rate for playback to sound correct
            resampledBuffer = audioContext.createBuffer(
                originalBuffer.numberOfChannels, 
                newLength, 
                originalBuffer.sampleRate // Use original sample rate for playback context
            );

            for (let channel = 0; channel < originalBuffer.numberOfChannels; channel++) {
                const originalData = originalBuffer.getChannelData(channel);
                const newData = resampledBuffer.getChannelData(channel);
                
                for (let i = 0; i < newLength; i++) {
                    const originalIndex = Math.floor(i * ratio); 
                    // Simple nearest neighbor interpolation
                    newData[i] = originalData[originalIndex];
                }
            }
        }
        
        // --- 3. Gender Classification (Placeholder - Assumes a server endpoint /voice/classify) ---
        
        async function classifyGender() {
            if (!uploadedFile) {
                messageBox.textContent = "No file uploaded!";
                return;
            }

            classifyBtn.disabled = true;
            messageBox.textContent = "Classifying gender... Please wait.";
            classificationResults.classList.add('hidden');
            // Remove previous gender classes
            classificationResults.classList.remove('results-male', 'results-female');
            genderAccentBar.classList.remove('gender-accent-bar-male', 'gender-accent-bar-female');


            const formData = new FormData();
            formData.append('audio', uploadedFile);

            try {
                // IMPORTANT: This 'fetch' call requires a backend server to handle the classification.
                // This is placeholder functionality for the frontend.
                const response = await fetch('/voice/classify', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                
                if (!response.ok) {
                    throw new Error(data.error || 'Classification failed');
                }
                
                // Display results
                updateClassificationUI(data.gender, data.confidence, data.pitch);
                
                messageBox.textContent = "Classification complete!";
            } catch (error) {
                messageBox.textContent = "Error: Classification failed. Check server (backend) connection. Showing mock data.";
                console.error('Classification error:', error);
                
                // --- Mock Data for Demo if no backend is available (Simulating a Female result) ---
                const mockGender = Math.random() < 0.5 ? 'male' : 'female';
                const mockConfidence = 0.85 + Math.random() * 0.1; // 85% to 95%
                const mockPitch = mockGender === 'male' ? 100 + Math.random() * 40 : 180 + Math.random() * 60;

                updateClassificationUI(mockGender, mockConfidence, mockPitch);
            } finally {
                classifyBtn.disabled = false;
            }
        }

        // NEW: Function to handle updating classification results UI based on gender
        function updateClassificationUI(gender, confidence, pitch) {
            const genderText = gender.toUpperCase();
            
            genderResult.textContent = genderText;
            confidenceResult.textContent = (confidence * 100).toFixed(1) + '%';
            pitchResult.textContent = pitch.toFixed(1) + ' Hz';

            // Reset classes
            classificationResults.classList.remove('results-male', 'results-female');
            genderAccentBar.classList.remove('gender-accent-bar-male', 'gender-accent-bar-female');

            // Apply new classes for visual flair
            if (gender === 'male') {
                classificationResults.classList.add('results-male');
                genderAccentBar.classList.add('gender-accent-bar-male');
                genderResult.className = 'text-2xl font-bold text-blue-400';
            } else if (gender === 'female') {
                classificationResults.classList.add('results-female');
                genderAccentBar.classList.add('gender-accent-bar-female');
                genderResult.className = 'text-2xl font-bold text-pink-400';
            } else {
                 genderResult.className = 'text-2xl font-bold text-white';
            }

            classificationResults.classList.remove('hidden');
        }
        
        // --- 4. Playback Functions ---
        
        function stopAudio() {
            if (currentSourceNode) {
                currentSourceNode.stop();
                currentSourceNode = null;
            }
            isPlaying = false;
            // Re-enable appropriate buttons
            if (originalBuffer) {
                playOriginalBtn.disabled = false;
                playSampledBtn.disabled = false;
                classifyBtn.disabled = false;
            }
            pauseBtn.disabled = true;
            messageBox.textContent = "Playback paused/stopped.";
        }
        
        function resetApp() {
            stopAudio();
            
            // Stop any ongoing recording
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            if (recordingStream) {
                recordingStream.getTracks().forEach(track => track.stop());
                recordingStream = null;
            }
            if (recordingTimerInterval) {
                clearInterval(recordingTimerInterval);
                recordingTimerInterval = null;
            }
            
            // Clear data
            originalBuffer = null;
            resampledBuffer = null;
            uploadedFile = null;
            isPlaying = false;
            currentSourceNode = null;
            audioChunks = [];
            recordingStartTime = null;
            
            // Reset recording UI
            recordBtn.disabled = false;
            recordBtn.classList.remove('record-btn-active');
            stopRecordBtn.disabled = true;
            recordingTimer.classList.add('hidden');
            recordingStatus.textContent = '';
            recordingStatus.classList.remove('recording-indicator');
            
            // Reset UI states
            controls.classList.add('opacity-50', 'pointer-events-none');
            playOriginalBtn.disabled = true;
            playSampledBtn.disabled = true;
            pauseBtn.disabled = true;
            resetBtn.disabled = true;
            classifyBtn.disabled = true;
            
            fileNameDisplay.classList.add('hidden');
            filePrompt.classList.remove('hidden');
            filePrompt.innerHTML = '**Drag & Drop** an MP3/WAV audio file here, or **click to upload**. ';
            
            // Reset slider to default/initial values
            const defaultRate = audioContext ? audioContext.sampleRate : 44100;
            frequencySlider.min = 4000;
            frequencySlider.max = defaultRate;
            frequencySlider.value = defaultRate;
            currentFrequencyDisplay.textContent = `${defaultRate} (Original Rate)`;
            
            classificationResults.classList.add('hidden');
            // Remove gender accent classes on full reset
            classificationResults.classList.remove('results-male', 'results-female');
            genderAccentBar.classList.remove('gender-accent-bar-male', 'gender-accent-bar-female');

            messageBox.textContent = "Application reset. Ready for new file.";
        }

        function playAudio(buffer) {
            if (isPlaying) {
                stopAudio();
            }
            initAudioContext();
            
            currentSourceNode = audioContext.createBufferSource();
            currentSourceNode.buffer = buffer;
            currentSourceNode.connect(audioContext.destination);
            
            currentSourceNode.onended = () => {
                if (isPlaying) {
                    isPlaying = false;
                    currentSourceNode = null;
                    playOriginalBtn.disabled = false;
                    playSampledBtn.disabled = false;
                    pauseBtn.disabled = true;
                    classifyBtn.disabled = false;
                    messageBox.textContent = "Playback finished.";
                }
            };

            currentSourceNode.start(0);
            isPlaying = true;
            playOriginalBtn.disabled = true;
            playSampledBtn.disabled = true;
            classifyBtn.disabled = true; // Disable classification during playback
            pauseBtn.disabled = false;
            messageBox.textContent = "Playing audio...";
        }

        // --- 5. Voice Recording Functions ---

        async function startRecording() {
            try {
                // Request microphone access
                recordingStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });

                audioChunks = [];
                
                // Create MediaRecorder with audio/webm format
                const options = { mimeType: 'audio/webm' };
                mediaRecorder = new MediaRecorder(recordingStream, options);

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    // Create blob from chunks
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    // Convert to WAV format
                    await convertToWavAndLoad(audioBlob);
                    
                    // Stop all tracks
                    if (recordingStream) {
                        recordingStream.getTracks().forEach(track => track.stop());
                        recordingStream = null;
                    }
                };

                // Start recording
                mediaRecorder.start();
                recordingStartTime = Date.now();
                
                // Update UI
                recordBtn.disabled = true;
                recordBtn.classList.add('record-btn-active');
                stopRecordBtn.disabled = false;
                recordingTimer.classList.remove('hidden');
                recordingStatus.textContent = 'üî¥ Recording...';
                recordingStatus.classList.add('recording-indicator');
                
                // Start timer
                recordingTimerInterval = setInterval(updateRecordingTimer, 100);
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                recordingStatus.textContent = 'Error: Could not access microphone. Please grant permission.';
                recordingStatus.classList.remove('recording-indicator');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                
                // Update UI
                recordBtn.disabled = false;
                recordBtn.classList.remove('record-btn-active');
                stopRecordBtn.disabled = true;
                recordingTimer.classList.add('hidden');
                recordingStatus.textContent = 'Processing recording...';
                recordingStatus.classList.remove('recording-indicator');
                
                // Stop timer
                if (recordingTimerInterval) {
                    clearInterval(recordingTimerInterval);
                    recordingTimerInterval = null;
                }
            }
        }

        function updateRecordingTimer() {
            if (recordingStartTime) {
                const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
                const minutes = Math.floor(elapsed / 60);
                const seconds = elapsed % 60;
                recordingTimer.textContent = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
            }
        }

        async function convertToWavAndLoad(webmBlob) {
            try {
                initAudioContext();
                
                // Read the webm blob as array buffer
                const arrayBuffer = await webmBlob.arrayBuffer();
                
                // Decode the audio data
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Convert AudioBuffer to WAV format
                const wavBlob = audioBufferToWav(audioBuffer);
                
                // Create a File object from the WAV blob
                const wavFile = new File([wavBlob], 'recorded_voice.wav', { type: 'audio/wav' });
                
                // Store for classification
                uploadedFile = wavFile;
                
                // Load into the app
                decodeAudio(wavFile);
                
                recordingStatus.textContent = '‚úì Recording saved successfully!';
                setTimeout(() => {
                    recordingStatus.textContent = '';
                }, 3000);
                
            } catch (error) {
                console.error('Error converting recording:', error);
                recordingStatus.textContent = 'Error processing recording.';
            }
        }

        function audioBufferToWav(buffer) {
            const length = buffer.length * buffer.numberOfChannels * 2 + 44;
            const arrayBuffer = new ArrayBuffer(length);
            const view = new DataView(arrayBuffer);
            const channels = [];
            let offset = 0;
            let pos = 0;

            // Write WAV header
            const setUint16 = (data) => {
                view.setUint16(pos, data, true);
                pos += 2;
            };
            const setUint32 = (data) => {
                view.setUint32(pos, data, true);
                pos += 4;
            };

            // "RIFF" chunk descriptor
            setUint32(0x46464952); // "RIFF"
            setUint32(length - 8); // file length - 8
            setUint32(0x45564157); // "WAVE"

            // "fmt " sub-chunk
            setUint32(0x20746d66); // "fmt "
            setUint32(16); // SubChunk1Size = 16
            setUint16(1); // AudioFormat = 1 (PCM)
            setUint16(buffer.numberOfChannels);
            setUint32(buffer.sampleRate);
            setUint32(buffer.sampleRate * buffer.numberOfChannels * 2); // ByteRate
            setUint16(buffer.numberOfChannels * 2); // BlockAlign
            setUint16(16); // BitsPerSample

            // "data" sub-chunk
            setUint32(0x61746164); // "data"
            setUint32(length - pos - 4); // SubChunk2Size

            // Write interleaved data
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                channels.push(buffer.getChannelData(i));
            }

            while (pos < length) {
                for (let i = 0; i < buffer.numberOfChannels; i++) {
                    let sample = Math.max(-1, Math.min(1, channels[i][offset]));
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    view.setInt16(pos, sample, true);
                    pos += 2;
                }
                offset++;
            }

            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }

        // --- 6. Event Listeners ---

        // Recording button handlers
        recordBtn.addEventListener('click', startRecording);
        stopRecordBtn.addEventListener('click', stopRecording);

        // File Input Change
        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                decodeAudio(e.target.files[0]);
            }
        });

        // Drag and Drop handlers
        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            dragDropArea.addEventListener(eventName, preventDefaults, false);
            document.body.addEventListener(eventName, preventDefaults, false);
        });

        function preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        ['dragenter', 'dragover'].forEach(eventName => {
            dragDropArea.addEventListener(eventName, () => dragDropArea.classList.add('drag-over'), false);
        });

        ['dragleave', 'drop'].forEach(eventName => {
            dragDropArea.addEventListener(eventName, () => dragDropArea.classList.remove('drag-over'), false);
        });

        dragDropArea.addEventListener('drop', (e) => {
            const dt = e.dataTransfer;
            const files = dt.files;
            if (files.length > 0 && files[0].type.startsWith('audio/')) {
                decodeAudio(files[0]);
            } else {
                messageBox.textContent = "Please drop a valid audio file (mp3, wav).";
            }
        }, false);

        // Slider Input Change
        frequencySlider.addEventListener('input', (e) => {
            const targetRate = parseInt(e.target.value, 10);
            currentFrequencyDisplay.textContent = targetRate;
            
            if (targetRate === originalRate) {
                currentFrequencyDisplay.textContent += ' (Original Rate)';
            } else if (targetRate < 8000) {
                currentFrequencyDisplay.textContent += ' (Severe Degradation)';
            }
            
            if (originalBuffer) {
                resampleAudio(targetRate);
            }
        });

        // Playback button handlers
        playOriginalBtn.addEventListener('click', () => {
            if (originalBuffer) {
                playAudio(originalBuffer);
            }
        });

        playSampledBtn.addEventListener('click', () => {
            if (resampledBuffer) {
                playAudio(resampledBuffer);
            }
        });
        
        // Control buttons
        pauseBtn.addEventListener('click', stopAudio);
        resetBtn.addEventListener('click', resetApp);
        classifyBtn.addEventListener('click', classifyGender);

        // Initial setup on load
        document.addEventListener('DOMContentLoaded', initAudioContext);
    </script>
</body>
</html>